{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominik Adamczyk\n",
    "## Laboratorium 2 - rozwiÄ…zania "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Implementacja statycznego algorytmu Huffmana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from heapq import heapify, heappop, heappush\n",
    "from bitarray import bitarray, frozenbitarray\n",
    "\n",
    "class Static_node:\n",
    "    def __init__(self, symbol, weight, left=None, right=None):\n",
    "        self.symbol = symbol\n",
    "        self.weight = weight\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.weight < other.weight\n",
    "    \n",
    "def static_huffman_traverse(codes, node, code=bitarray()):\n",
    "    if node.symbol is not None:\n",
    "        codes[node.symbol] = frozenbitarray(code)\n",
    "    else:\n",
    "        static_huffman_traverse(codes, node.left, code + bitarray('0'))\n",
    "        static_huffman_traverse(codes, node.right, code + bitarray('1'))\n",
    "\n",
    "def static_huffman_encoding(data):\n",
    "    freq = Counter(data)\n",
    "    heap = [Static_node(symbol, weight) for symbol, weight in freq.items()]\n",
    "    \n",
    "    heapify(heap)\n",
    "    \n",
    "    while len(heap) > 1:\n",
    "        node1 = heappop(heap)\n",
    "        node2 = heappop(heap)\n",
    "        merged = Static_node(None, node1.weight + node2.weight, node1, node2)\n",
    "        heappush(heap, merged)\n",
    "\n",
    "    codes = {}\n",
    "    static_huffman_traverse(codes, heap[0])\n",
    "\n",
    "    encoded_data = bitarray()\n",
    "    for symbol in data:\n",
    "        encoded_data += codes[symbol] \n",
    "    codes =  {code: symbol for symbol, code in codes.items()}\n",
    "\n",
    "    return encoded_data, codes\n",
    "\n",
    "def static_huffman_decoding(encoded_data, codes):\n",
    "    encoded_data = encoded_data.to01()\n",
    "    decoded_data = ''\n",
    "    code = ''\n",
    "    for bit in encoded_data:\n",
    "        # print\n",
    "        code += bit\n",
    "        if code in codes:\n",
    "            decoded_data += codes[code]\n",
    "            code = ''\n",
    "    return decoded_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Implementacja dynamicznego algorytmu Huffmana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naprawianie\n",
    "from bitarray import bitarray\n",
    "class AdaptiveNode:\n",
    "    def __init__(self, symbol=None, weight=None,parent=None, left=None, right=None, order=None):\n",
    "        self.symbol = symbol\n",
    "        self.weight = weight\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.parent = parent\n",
    "        self.order = order\n",
    "    \n",
    "\n",
    "class AdaptiveHuffmanTree:\n",
    "    def __init__(self):\n",
    "        self.order = 1\n",
    "        self.zero = AdaptiveNode(weight=0, order=1, symbol='Zero')\n",
    "        self.root = self.zero\n",
    "        self.leaves = {'Zero' : self.zero}\n",
    "        self.weights = {key: set() for key in range(2)}\n",
    "        self.weights[0].add(self.root)\n",
    "    \n",
    "    def create_node(self, symbol):\n",
    "        zero = self.zero\n",
    "        zero.left = AdaptiveNode(weight=0, order=2*zero.order, parent=zero, symbol='Zero')\n",
    "        zero.right = AdaptiveNode(weight=1, order=2*zero.order+1, parent=zero, symbol=symbol)\n",
    "        zero.symbol = None\n",
    "        self.zero = zero.left\n",
    "        self.weights[0].add(zero.left)\n",
    "        self.weights[1].add(zero.right)\n",
    "        self.leaves[symbol] = zero.right\n",
    "        self.leaves['Zero'] = zero.left\n",
    "        self.update_tree(zero)\n",
    "    \n",
    "    def reconstruct_order(self, node):\n",
    "        if node.left != None:\n",
    "            node.left.order = 2 * node.order\n",
    "            self.reconstruct_order(node.left)\n",
    "        if node.right != None:\n",
    "            node.right.order = 2 * node.order + 1\n",
    "            self.reconstruct_order(node.right)\n",
    "        \n",
    "    def swap_nodes(self, n1, n2):\n",
    "        if n1 != n2:\n",
    "            if n1.parent == n2.parent:\n",
    "                if n1 == n1.parent.left:\n",
    "                    n1.parent.right = n1\n",
    "                    n1.parent.left = n2\n",
    "                else:\n",
    "                    n1.parent.left = n1\n",
    "                    n1.parent.right = n2\n",
    "            else:\n",
    "                if n1 == n1.parent.left:\n",
    "                    n1.parent.left = n2\n",
    "                else:\n",
    "                    n1.parent.right = n2\n",
    "                if n2 == n2.parent.left:\n",
    "                    n2.parent.left = n1\n",
    "                else:\n",
    "                    n2.parent.right = n1\n",
    "\n",
    "                n1.parent, n2.parent = n2.parent, n1.parent\n",
    "            n1.order, n2.order = n2.order, n1.order\n",
    "            self.reconstruct_order(n1)\n",
    "            self.reconstruct_order(n2)\n",
    "            \n",
    "    \n",
    "    def update_tree(self, node):\n",
    "        while node != self.root:\n",
    "            same_val_node = min(self.weights[node.weight], key=lambda x:x.order)\n",
    "            if same_val_node != self.root and not self.is_ancestor(node, same_val_node):\n",
    "                self.swap_nodes(node, same_val_node)\n",
    "            self.weights[same_val_node.weight].remove(node)\n",
    "            node.weight += 1\n",
    "            if node.weight not in self.weights:\n",
    "                self.weights[node.weight] = set()\n",
    "            self.weights[node.weight].add(node)\n",
    "            node = node.parent\n",
    "    \n",
    "    def is_ancestor(self, child, ancestor):\n",
    "        while child != self.root:\n",
    "            if child == ancestor:\n",
    "                return True\n",
    "            child = child.parent\n",
    "        return False\n",
    "            \n",
    "    def get_code(self, symbol):\n",
    "        node = self.leaves[symbol]\n",
    "        code = ''\n",
    "        while node.parent != None:\n",
    "            if node == node.parent.right:\n",
    "                code += '1'\n",
    "            else:\n",
    "                code += '0'\n",
    "            node = node.parent\n",
    "        return bitarray(code[::-1])\n",
    "    \n",
    "    def get_symbol(self, code):\n",
    "        node = self.root\n",
    "        for el in code:\n",
    "            if el == '1':\n",
    "                node = node.right\n",
    "            else:\n",
    "                node = node.left\n",
    "        return node\n",
    "    \n",
    "    def encode(self, text):\n",
    "        encoded = bitarray()\n",
    "        codebook = []\n",
    "        for symbol in text:\n",
    "            if symbol in self.leaves:\n",
    "                encoded += self.get_code(symbol)\n",
    "                self.update_tree(self.leaves[symbol])\n",
    "                \n",
    "            else:\n",
    "                codebook.append((symbol, self.get_code('Zero')))\n",
    "                encoded += self.get_code('Zero')\n",
    "                self.create_node(symbol)\n",
    "        return encoded, codebook\n",
    "\n",
    "    def decode(self, codebook, bits):\n",
    "        codes = [code.to01() for _, code in codebook]\n",
    "        bits = bits.to01()\n",
    "        decoded = ''\n",
    "        node = self.root\n",
    "        idx = 0\n",
    "        while idx < len(bits):\n",
    "            while not (node.left is None and node.right is None):\n",
    "                if bits[idx] == '0':\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "                idx += 1\n",
    "            if node.symbol == 'Zero':\n",
    "                symbol = codebook[codes.index(self.get_code('Zero').to01())][0]\n",
    "                codes[codes.index(self.get_code('Zero').to01())] = None\n",
    "                self.create_node(symbol)\n",
    "            else:\n",
    "                symbol = node.symbol\n",
    "                self.update_tree(node)\n",
    "            decoded += symbol\n",
    "            node = self.root\n",
    "        return decoded\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Opracowanie typu oraz algorytmu kompresji i dekompresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def encode_file(filename, static=True):\n",
    "    with open(\"text_files/\" + filename + \".txt\", \"r\") as f:\n",
    "        text = f.read()\n",
    "    if static:\n",
    "        text_coded, decode_tree = static_huffman_encoding(text)\n",
    "        with open(\"compressed_files/\" + filename + \".bin\", \"wb+\") as f:\n",
    "            num_entries = len(decode_tree)\n",
    "            header = struct.pack(\"i\", num_entries)\n",
    "            f.write(header)\n",
    "            bits_to_omit = 0 if len(text_coded) % 8 == 0 else 8 - len(text_coded) % 8\n",
    "            header2 = struct.pack(\"B\", bits_to_omit)\n",
    "            f.write(header2)\n",
    "            for code, letter in decode_tree.items():\n",
    "                code_len = len(code)\n",
    "                f.write(struct.pack('B', code_len))\n",
    "                code_bytes = code.tobytes()\n",
    "                f.write(code_bytes)\n",
    "                letter_bytes = letter.encode(\"utf-16-le\")\n",
    "                entry = struct.pack(f'2s', letter_bytes)\n",
    "                # letter_len = len(letter_bytes)\n",
    "                # entry = struct.pack(f'B{letter_len}s', letter_len, letter_bytes)\n",
    "                f.write(entry)\n",
    "            text_coded.tofile(f)\n",
    "    else:\n",
    "        encoded, codebook = AdaptiveHuffmanTree().encode(text)\n",
    "        num_entries = len(codebook)\n",
    "        header = struct.pack(\"i\", num_entries)\n",
    "        bits_to_omit = 0 if len(encoded) % 8 == 0 else 8 - len(encoded) % 8\n",
    "        header2 = struct.pack(\"B\", bits_to_omit)\n",
    "        with open(\"compressed_files/\" + filename + \".bin\", \"wb+\") as f:\n",
    "            f.write(header)\n",
    "            f.write(header2)\n",
    "            for letter, code in codebook:\n",
    "                code_len = len(code)\n",
    "                f.write(struct.pack('B', code_len))\n",
    "                code_bytes = code.tobytes()\n",
    "                f.write(code_bytes)\n",
    "                \n",
    "                letter_bytes = letter.encode(\"utf-16-le\")\n",
    "                # print(len(letter_bytes))\n",
    "                entry = struct.pack(f'2s', letter_bytes)\n",
    "                # letter_len = len(letter_bytes)\n",
    "                # entry = struct.pack(f'B{letter_len}s', letter_len, letter_bytes)\n",
    "                f.write(entry)\n",
    "            encoded.tofile(f)\n",
    "            \n",
    "def decode_file(filename, static=True):\n",
    "    if static:\n",
    "        with open(\"compressed_files/\" + filename + \".bin\", \"rb\") as f:\n",
    "            header = f.read(4)\n",
    "            num_entries = struct.unpack('i', header)[0]\n",
    "            header = f.read(1)\n",
    "            bits_to_omit = struct.unpack('B', header)[0]\n",
    "            decode_tree = {}\n",
    "            for _ in range(num_entries):\n",
    "                len_bits = f.read(1)\n",
    "                len_bits = struct.unpack('B', len_bits)[0]\n",
    "                code = bitarray()\n",
    "                code.fromfile(f, (len_bits + 7) // 8)\n",
    "                code = code [:len_bits]\n",
    "                # len_letter = f.read(1)\n",
    "                # len_letter = struct.unpack('B', len_letter)[0]\n",
    "                letter_bytes = f.read(2)\n",
    "                letter = letter_bytes.decode(\"utf-16-le\")\n",
    "                decode_tree[code.to01()] = letter\n",
    "            coded_data = bitarray()\n",
    "            coded_data.fromfile(f)\n",
    "            if bits_to_omit != 0:\n",
    "                coded_data = coded_data[:-bits_to_omit]\n",
    "        text = static_huffman_decoding(coded_data, decode_tree) \n",
    "    else:\n",
    "        with open(\"compressed_files/\" + filename + \".bin\", \"rb\") as f:\n",
    "            header = f.read(4)\n",
    "            num_entries = struct.unpack('i', header)[0]\n",
    "            header = f.read(1)\n",
    "            bits_to_omit = struct.unpack('B', header)[0]\n",
    "            codebook = []\n",
    "            for _ in range(num_entries):\n",
    "                len_bits = f.read(1)\n",
    "                len_bits = struct.unpack('B', len_bits)[0]\n",
    "                code = bitarray()\n",
    "                code.fromfile(f, (len_bits + 7) // 8)\n",
    "                code = code [:len_bits]\n",
    "                # len_letter = f.read(1)\n",
    "                # len_letter = struct.unpack('B', len_letter)[0]\n",
    "                letter_bytes = f.read(2)\n",
    "                letter = letter_bytes.decode(\"utf-16-le\")\n",
    "                codebook.append((letter, bitarray(code)))\n",
    "            encoded = bitarray()\n",
    "            encoded.fromfile(f)\n",
    "            if bits_to_omit != 0:\n",
    "                encoded = encoded[:-bits_to_omit]\n",
    "        text = AdaptiveHuffmanTree().decode(codebook, encoded)\n",
    "    with open(\"decompressed_files/\" + filename + \".txt\", \"w+\") as f:\n",
    "        f.write(text)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funkcje pomocnicze - mierzenie czasu, porÃ³wnaywanie plikÃ³w, generowanie plikÃ³w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, time\n",
    "import os\n",
    "\n",
    "def file_compare(filename):\n",
    "    with open(\"text_files/\" + filename + \".txt\", \"r\") as f1, open(\"decompressed_files/\" + filename + \".txt\", \"r\") as f2:\n",
    "        f1_cont = f1.read()\n",
    "        f2_cont = f2.read()\n",
    "        if f1_cont == f2_cont:\n",
    "            print(f\"Initial, and decompressed file '{filename}.txt' are the same\")\n",
    "        else:\n",
    "            print(f\"Initial, and decompressed file '{filename}.txt' are not the same \")\n",
    "    print('\\n')\n",
    "\n",
    "def compare_size(filename):\n",
    "    original_size = os.path.getsize(\"text_files/\" + filename + \".txt\")\n",
    "    comp_size = os.path.getsize(\"compressed_files/\" + filename + \".bin\")\n",
    "    ratio = (1 - (comp_size / original_size)) * 100\n",
    "    return ratio\n",
    "\n",
    "def test_compression(filename, static=True):\n",
    "    if not static:\n",
    "        filename += 'Adaptive'\n",
    "    print((\"[Static]\" if static else \"[Adaptive]\") + f\"\\n[Filename] {filename}.txt\" )\n",
    "    t = time.time()\n",
    "    encode_file(filename, static)\n",
    "    print(f'[Encoding time] {time.time() - t}s')\n",
    "    t = time.time()\n",
    "    decode_file(filename, static)\n",
    "    print(f'[Decoding time] {time.time() - t}s')\n",
    "    print(f'[Compression ratio] {compare_size(filename)}%')\n",
    "    file_compare(filename)\n",
    "\n",
    "def generate_uniform_unicode_text(filename, num_chars):\n",
    "    uni_chars = [chr(i) for i in range(150)]\n",
    "    \n",
    "    text = ''.join(random.choices(uni_chars, k = num_chars))\n",
    "    # print(text)\n",
    "    with open(\"text_files/\" + filename + \".txt\", 'w') as f:\n",
    "        f.write(text)\n",
    "\n",
    "# test_compression('uniform100kb', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_tests = ['uniform1kb',\n",
    "                 'uniform10kb',\n",
    "                 'uniform100kb',\n",
    "                 'uniform1mb']\n",
    "for num, name in enumerate(uniform_tests):\n",
    "    generate_uniform_unicode_text(name, 910 * 10 ** num)\n",
    "linux_tests = ['halbtc8821a2antc1kb',\n",
    "               'halbtc8821a2antc10kb',\n",
    "               'halbtc8821a2antc100kb',\n",
    "               'halbtc8821a2antc1mb']\n",
    "book_tests = ['theBrothersKaramazov1kb',\n",
    "              'theBrothersKaramazov10kb',\n",
    "              'theBrothersKaramazov100kb',\n",
    "              'theBrothersKaramazov1mb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Static]\n",
      "[Filename] uniform1kb.txt\n",
      "[Encoding time] 0.008971929550170898s\n",
      "[Decoding time] 0.005411863327026367s\n",
      "[Compression ratio] -35.30534351145038%\n",
      "Initial, and decompressed file 'uniform1kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] uniform1kbAdaptive.txt\n",
      "[Encoding time] 0.023917198181152344s\n",
      "[Decoding time] 0.02394556999206543s\n",
      "[Compression ratio] -42.583732057416256%\n",
      "Initial, and decompressed file 'uniform1kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] uniform10kb.txt\n",
      "[Encoding time] 0.006046772003173828s\n",
      "[Decoding time] 0.01335000991821289s\n",
      "[Compression ratio] 15.9147154007234%\n",
      "Initial, and decompressed file 'uniform10kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] uniform10kbAdaptive.txt\n",
      "[Encoding time] 0.14896774291992188s\n",
      "[Decoding time] 0.14234495162963867s\n",
      "[Compression ratio] 14.65574707170746%\n",
      "Initial, and decompressed file 'uniform10kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] uniform100kb.txt\n",
      "[Encoding time] 0.019339323043823242s\n",
      "[Decoding time] 0.09059524536132812s\n",
      "[Compression ratio] 20.8355523432745%\n",
      "Initial, and decompressed file 'uniform100kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] uniform100kbAdaptive.txt\n",
      "[Encoding time] 1.423311710357666s\n",
      "[Decoding time] 1.2490651607513428s\n",
      "[Compression ratio] 20.26565392469322%\n",
      "Initial, and decompressed file 'uniform100kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] uniform1mb.txt\n",
      "[Encoding time] 0.15169262886047363s\n",
      "[Decoding time] 0.8609495162963867s\n",
      "[Compression ratio] 21.08177845704692%\n",
      "Initial, and decompressed file 'uniform1mb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] uniform1mbAdaptive.txt\n",
      "[Encoding time] 17.039754152297974s\n",
      "[Decoding time] 20.5737247467041s\n",
      "[Compression ratio] 20.940100895942248%\n",
      "Initial, and decompressed file 'uniform1mbAdaptive.txt' are the same\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in uniform_tests:\n",
    "    test_compression(name)\n",
    "    test_compression(name, False)\n",
    "    # test_compression(name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Static]\n",
      "[Filename] theBrothersKaramazov1kb.txt\n",
      "[Encoding time] 0.002365589141845703s\n",
      "[Decoding time] 0.009876728057861328s\n",
      "[Compression ratio] 13.829787234042556%\n",
      "Initial, and decompressed file 'theBrothersKaramazov1kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] theBrothersKaramazov1kbAdaptive.txt\n",
      "[Encoding time] 0.02613687515258789s\n",
      "[Decoding time] 0.03031134605407715s\n",
      "[Compression ratio] 11.605415860735013%\n",
      "Initial, and decompressed file 'theBrothersKaramazov1kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] theBrothersKaramazov10kb.txt\n",
      "[Encoding time] 0.007334232330322266s\n",
      "[Decoding time] 0.02505660057067871s\n",
      "[Compression ratio] 39.03241412675374%\n",
      "Initial, and decompressed file 'theBrothersKaramazov10kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] theBrothersKaramazov10kbAdaptive.txt\n",
      "[Encoding time] 0.184983491897583s\n",
      "[Decoding time] 0.15694093704223633s\n",
      "[Compression ratio] 38.80986937590711%\n",
      "Initial, and decompressed file 'theBrothersKaramazov10kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] theBrothersKaramazov100kb.txt\n",
      "[Encoding time] 0.021671056747436523s\n",
      "[Decoding time] 0.11687445640563965s\n",
      "[Compression ratio] 45.01489398983705%\n",
      "Initial, and decompressed file 'theBrothersKaramazov100kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] theBrothersKaramazov100kbAdaptive.txt\n",
      "[Encoding time] 1.4071588516235352s\n",
      "[Decoding time] 1.403364896774292s\n",
      "[Compression ratio] 44.99055740513599%\n",
      "Initial, and decompressed file 'theBrothersKaramazov100kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] theBrothersKaramazov1mb.txt\n",
      "[Encoding time] 0.2892587184906006s\n",
      "[Decoding time] 1.1515295505523682s\n",
      "[Compression ratio] 45.6020602107585%\n",
      "Initial, and decompressed file 'theBrothersKaramazov1mb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] theBrothersKaramazov1mbAdaptive.txt\n",
      "[Encoding time] 14.172238111495972s\n",
      "[Decoding time] 13.73476243019104s\n",
      "[Compression ratio] 45.59770178108177%\n",
      "Initial, and decompressed file 'theBrothersKaramazov1mbAdaptive.txt' are the same\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in book_tests:\n",
    "    test_compression(name)\n",
    "    test_compression(name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Static]\n",
      "[Filename] halbtc8821a2antc1kb.txt\n",
      "[Encoding time] 0.004037618637084961s\n",
      "[Decoding time] 0.00599980354309082s\n",
      "[Compression ratio] 26.356589147286826%\n",
      "Initial, and decompressed file 'halbtc8821a2antc1kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] halbtc8821a2antc1kbAdaptive.txt\n",
      "[Encoding time] 0.019855737686157227s\n",
      "[Decoding time] 0.020258426666259766s\n",
      "[Compression ratio] 26.25968992248062%\n",
      "Initial, and decompressed file 'halbtc8821a2antc1kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] halbtc8821a2antc10kb.txt\n",
      "[Encoding time] 0.004001617431640625s\n",
      "[Decoding time] 0.019162654876708984s\n",
      "[Compression ratio] 30.28031925248199%\n",
      "Initial, and decompressed file 'halbtc8821a2antc10kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] halbtc8821a2antc10kbAdaptive.txt\n",
      "[Encoding time] 0.1912994384765625s\n",
      "[Decoding time] 0.15654754638671875s\n",
      "[Compression ratio] 29.7839205762118%\n",
      "Initial, and decompressed file 'halbtc8821a2antc10kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] halbtc8821a2antc100kb.txt\n",
      "[Encoding time] 0.02205801010131836s\n",
      "[Decoding time] 0.15250802040100098s\n",
      "[Compression ratio] 33.94745820539066%\n",
      "Initial, and decompressed file 'halbtc8821a2antc100kb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] halbtc8821a2antc100kbAdaptive.txt\n",
      "[Encoding time] 1.6633954048156738s\n",
      "[Decoding time] 1.728454351425171s\n",
      "[Compression ratio] 33.88214651264805%\n",
      "Initial, and decompressed file 'halbtc8821a2antc100kbAdaptive.txt' are the same\n",
      "\n",
      "\n",
      "[Static]\n",
      "[Filename] halbtc8821a2antc1mb.txt\n",
      "[Encoding time] 0.24489521980285645s\n",
      "[Decoding time] 1.1478097438812256s\n",
      "[Compression ratio] 33.656927543159334%\n",
      "Initial, and decompressed file 'halbtc8821a2antc1mb.txt' are the same\n",
      "\n",
      "\n",
      "[Adaptive]\n",
      "[Filename] halbtc8821a2antc1mbAdaptive.txt\n",
      "[Encoding time] 17.350225925445557s\n",
      "[Decoding time] 14.380632877349854s\n",
      "[Compression ratio] 33.6484867797729%\n",
      "Initial, and decompressed file 'halbtc8821a2antc1mbAdaptive.txt' are the same\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in linux_tests:\n",
    "    test_compression(name)\n",
    "    test_compression(name, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
